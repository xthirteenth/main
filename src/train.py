import torch
import torch.nn as nn
import torch.optim as optim
import sys

def print_progress_bar(iteration, total, prefix='', suffix='', decimals=1, length=50, fill='‚ñà', print_end="\r"):
    """
    –ü—Ä–æ—Å—Ç–æ–π –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –±–µ–∑ –≤–Ω–µ—à–Ω–∏—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫
    """
    percent = ("{0:." + str(decimals) + "f}").format(100 * (iteration / float(total)))
    filled_length = int(length * iteration // total)
    bar = fill * filled_length + '-' * (length - filled_length)
    print(f'\r{prefix} |{bar}| {percent}% {suffix}', end=print_end)
    sys.stdout.flush()
    if iteration == total:
        print()

def train_model(model, train_loader, val_loader, criterion, optimizer, epochs, patience=5, device='cpu'):
    best_val_loss = float('inf')
    patience_counter = 0
    
    for epoch in range(epochs):
        print(f"\nüöÄ –≠–ø–æ—Ö–∞ {epoch+1}/{epochs}")
        
        # –û–±—É—á–µ–Ω–∏–µ
        model.train()
        total_loss = 0.0
        correct = 0
        total_samples = 0
        
        for batch_idx, (images, labels) in enumerate(train_loader):
            images, labels = images.to(device), labels.to(device)
            
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total_samples += labels.size(0)
            correct += (predicted == labels).sum().item()
            
            # –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
            print_progress_bar(
                batch_idx + 1, 
                len(train_loader), 
                prefix='–û–±—É—á–µ–Ω–∏–µ:', 
                suffix=f'–ü–æ—Ç–µ—Ä—è: {loss.item():.4f}, –¢–æ—á–Ω–æ—Å—Ç—å: {100 * correct / total_samples:.2f}%'
            )
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è
        model.eval()
        val_loss = 0.0
        correct_val = 0
        total_val_samples = 0
        
        with torch.no_grad():
            for batch_idx, (images, labels) in enumerate(val_loader):
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)
                val_loss += criterion(outputs, labels).item()
                
                _, predicted = torch.max(outputs.data, 1)
                total_val_samples += labels.size(0)
                correct_val += (predicted == labels).sum().item()
                
                # –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –≤–∞–ª–∏–¥–∞—Ü–∏–∏
                print_progress_bar(
                    batch_idx + 1, 
                    len(val_loader), 
                    prefix='–í–∞–ª–∏–¥–∞—Ü–∏—è:', 
                    suffix=f'–ü–æ—Ç–µ—Ä—è: {val_loss / (batch_idx + 1):.4f}, –¢–æ—á–Ω–æ—Å—Ç—å: {100 * correct_val / total_val_samples:.2f}%'
                )
        
        # –ú–µ—Ç—Ä–∏–∫–∏ —ç–ø–æ—Ö–∏
        train_accuracy = 100 * correct / total_samples
        val_loss /= len(val_loader)
        val_accuracy = 100 * correct_val / total_val_samples
        
        print(f"üìä –ú–µ—Ç—Ä–∏–∫–∏ —ç–ø–æ—Ö–∏:")
        print(f"   –û–±—É—á–µ–Ω–∏–µ - –ü–æ—Ç–µ—Ä—è: {total_loss / len(train_loader):.4f}, –¢–æ—á–Ω–æ—Å—Ç—å: {train_accuracy:.2f}%")
        print(f"   –í–∞–ª–∏–¥–∞—Ü–∏—è - –ü–æ—Ç–µ—Ä—è: {val_loss:.4f}, –¢–æ—á–Ω–æ—Å—Ç—å: {val_accuracy:.2f}%")
        
        # Early stopping
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            patience_counter = 0
            torch.save(model.state_dict(), 'best_model.pth')
            print("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å")
        else:
            patience_counter += 1
        
        if patience_counter >= patience:
            print(f"üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ–±—É—á–µ–Ω–∏—è. –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è –ø–æ—Ç–µ—Ä—è –Ω–µ —É–ª—É—á—à–∞–µ—Ç—Å—è {patience} —ç–ø–æ—Ö.")
            break
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
    model.load_state_dict(torch.load('best_model.pth'))
    return model